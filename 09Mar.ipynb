{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c81466d1",
   "metadata": {},
   "source": [
    "### Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462d7537",
   "metadata": {},
   "source": [
    "The Probability Mass Function (PMF) and Probability Density Function (PDF) are two fundamental concepts in probability theory that describe how the probability is distributed over a range of values for a discrete random variable (in the case of the PMF) or a continuous random variable (in the case of the PDF).\n",
    "\n",
    "The PMF is a function that gives the probability of each possible outcome of a discrete random variable. It maps each value of the random variable to its probability of occurrence. The sum of the PMF over all possible values of the random variable is equal to 1. An example of a PMF is the coin toss experiment, where the random variable X is the number of heads obtained in two tosses of a fair coin. \n",
    "\n",
    "On the other hand, the PDF is a function that gives the probability density of each possible value of a continuous random variable. It describes the relative likelihood of the random variable taking on a particular value. The area under the PDF over a range of values gives the probability of the random variable taking on a value within that range. An example of a PDF is the normal distribution, which is used to model many natural phenomena such as heights, weights, and IQ scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937aefbe",
   "metadata": {},
   "source": [
    "### Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3dd1c7",
   "metadata": {},
   "source": [
    "The Cumulative Density Function (CDF) is a function that gives the probability that a continuous random variable takes a value less than or equal to a given input value. It is defined as the integral of the Probability Density Function (PDF) from negative infinity up to the input value. For a discrete random variable, the CDF is defined as the sum of the Probability Mass Function (PMF) up to the input value.\n",
    "\n",
    "The CDF is useful because it provides a complete description of the probability distribution of a random variable. It allows us to calculate probabilities for a wide range of events or outcomes, such as the probability that the random variable falls within a certain interval or the probability that it takes on a specific value.\n",
    "\n",
    "In summary, the CDF is a function that gives us a complete description of the probability distribution of a random variable. It is used to calculate probabilities of events or outcomes and to make statistical inferences based on the properties of the probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3c1642",
   "metadata": {},
   "source": [
    "### Q3: What are some examples of situations where the normal distribution might be used as a model? Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd5a34d",
   "metadata": {},
   "source": [
    "Some examples of situations where the normal distribution might be used as a model are:\n",
    "\n",
    "* Heights and weights of people: The normal distribution is often used to model the distribution of heights and weights of people. In this case, the mean and standard deviation of the distribution can provide useful information about the average height and weight of a population, as well as the spread of the data around the mean.\n",
    "\n",
    "* Test scores: The normal distribution is often used to model the distribution of test scores, where the mean represents the average score and the standard deviation represents the spread of the scores around the mean.\n",
    "\n",
    "* Measurement errors: The normal distribution is often used to model measurement errors in scientific experiments and engineering applications. In this case, the mean and standard deviation can provide information about the precision and accuracy of the measurements.\n",
    "\n",
    "The parameters of the normal distribution are the mean (μ) and the standard deviation (σ). The mean represents the center of the distribution, while the standard deviation represents the spread of the data around the mean. The shape of the normal distribution is symmetric and bell-shaped, with the highest point located at the mean. The standard deviation determines the width of the distribution, with larger values of σ resulting in a wider distribution and smaller values of σ resulting in a narrower distribution.\n",
    "\n",
    "The normal distribution is characterized by the 68-95-99.7 rule, which states that approximately 68% of the data falls within one standard deviation of the mean, approximately 95% of the data falls within two standard deviations of the mean, and approximately 99.7% of the data falls within three standard deviations of the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0eed24",
   "metadata": {},
   "source": [
    "### Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b35e64",
   "metadata": {},
   "source": [
    "The normal distribution is an important statistical concept that has many practical applications in various fields of study. Some of the main reasons why the normal distribution is important are:\n",
    "\n",
    "* It is widely used as a model for natural and social phenomena: The normal distribution is a bell-shaped curve that describes the pattern of many natural and social phenomena. It is commonly used as a model to predict future events and make decisions based on probabilities.\n",
    "\n",
    "* It allows us to make statistical inferences: The normal distribution is well studied and understood, which means that we can use it to make inferences about population parameters, such as the mean and variance, from sample data.\n",
    "\n",
    "* It provides a basis for hypothesis testing: The normal distribution is used as the basis for many hypothesis tests, which are used to determine whether there is a statistically significant difference between two sets of data.\n",
    "\n",
    "Some real-life examples of normal distribution include:\n",
    "\n",
    "* Height and weight of people: The distribution of heights and weights of people in a population is often modeled using the normal distribution. This allows us to make inferences about the average height and weight of a population and to estimate the range of values that are likely to occur.\n",
    "\n",
    "* Test scores: The distribution of test scores is often modeled using the normal distribution. This allows us to compare the performance of different groups of students and to determine whether there is a significant difference in their test scores.\n",
    "\n",
    "* Stock prices: The daily percentage change in stock prices is often modeled using the normal distribution. This allows investors to estimate the probability of different levels of price change and to make informed decisions about buying or selling stocks.\n",
    "\n",
    "* IQ scores: IQ scores are often modeled using the normal distribution. This allows us to compare the intelligence of different individuals and to determine whether there is a significant difference in their scores.\n",
    "\n",
    "* Reaction times: The distribution of reaction times is often modeled using the normal distribution. This allows us to estimate the average reaction time and to determine the range of values that are likely to occur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ba904f",
   "metadata": {},
   "source": [
    "### Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a648cc",
   "metadata": {},
   "source": [
    "The Bernoulli distribution is a probability distribution that models the outcomes of a single binary experiment, where there are only two possible outcomes, often referred to as success or failure. The Bernoulli distribution is named after Swiss mathematician Jacob Bernoulli, who first introduced it in 1713.\n",
    "\n",
    "The probability mass function (PMF) of the Bernoulli distribution is given by:\n",
    "\n",
    "P(X = 1) = p, for x = 1 (success)\n",
    "P(X = 0) = 1 - p, for x = 0 (failure)\n",
    "\n",
    "where p is the probability of success.\n",
    "\n",
    "A simple example of the Bernoulli distribution is a coin toss, where the outcome can be either heads (success) or tails (failure). If we assume that the probability of getting heads is p = 0.5, then the probability of getting tails is 1 - p = 0.5.\n",
    "\n",
    "The difference between the Bernoulli distribution and the binomial distribution is that the Bernoulli distribution models the outcome of a single binary experiment, while the binomial distribution models the outcome of multiple binary experiments. In other words, the Bernoulli distribution is a special case of the binomial distribution where n = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ee67cc",
   "metadata": {},
   "source": [
    "### Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greater than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d13256b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that a randomly selected observation will be greater than 60 is: 0.15865525393145707\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# Set the mean and standard deviation\n",
    "mu = 50\n",
    "sigma = 10\n",
    "\n",
    "# Set the value we want to find the probability for\n",
    "x = 60\n",
    "\n",
    "# Calculate the z-score\n",
    "z = (x - mu) / sigma\n",
    "\n",
    "# Calculate the probability using the cumulative distribution function (CDF)\n",
    "prob = 1 - norm.cdf(z)\n",
    "\n",
    "# Print the result\n",
    "print(\"The probability that a randomly selected observation will be greater than 60 is:\", prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dd6aba",
   "metadata": {},
   "source": [
    "### Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a72cc6c",
   "metadata": {},
   "source": [
    "Uniform distribution is a probability distribution in which all values within a certain range are equally likely to occur. In other words, it describes a situation where the probability of any particular outcome is the same as the probability of any other outcome within the range.\n",
    "\n",
    "An example of a uniform distribution is rolling a fair six-sided die. Each face of the die has an equal probability of showing up, so the probability of rolling any number from 1 to 6 is 1/6. This is an example of a discrete uniform distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d8e881",
   "metadata": {},
   "source": [
    "### Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf5d603",
   "metadata": {},
   "source": [
    "The z-score, also known as the standard score, is a measure of how many standard deviations an observation or data point is away from the mean of a population or sample. It is calculated by subtracting the mean from the observation and then dividing the difference by the standard deviation:\n",
    "\n",
    "z = (x - mu) / sigma\n",
    "\n",
    "where x is the observation, mu is the mean, and sigma is the standard deviation.\n",
    "\n",
    "The z-score can be positive, negative, or zero, indicating whether the observation is above, below, or equal to the mean, respectively. A z-score of 1 indicates that the observation is one standard deviation above the mean, while a z-score of -2 indicates that the observation is two standard deviations below the mean, and so on.\n",
    "\n",
    "The importance of the z-score lies in its ability to standardize different data sets, which can have different scales and units, into a common scale. This allows us to compare observations from different data sets and to make meaningful conclusions about how unusual or extreme an observation is relative to the rest of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30502585",
   "metadata": {},
   "source": [
    "### Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50a488b",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental concept in statistics that states that the distribution of the sample means from any population, regardless of the shape of the population distribution, tends to follow a normal distribution as the sample size increases.\n",
    "\n",
    "The CLT has several important implications:\n",
    "\n",
    "It allows us to make inferences about a population based on a sample. For example, if we take repeated samples from a population and calculate the sample means, the distribution of those sample means will be normal. This means we can use the properties of the normal distribution to estimate population parameters, such as the mean and standard deviation.\n",
    "\n",
    "It explains why the normal distribution is so commonly used in statistical analysis. Many real-world phenomena follow a normal distribution, and the CLT explains why this is the case.\n",
    "\n",
    "It provides a framework for hypothesis testing and confidence intervals. By assuming that the sample means are normally distributed, we can calculate the probability of observing a sample mean given a null hypothesis and compare it to a significance level to determine whether to reject or fail to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6359998",
   "metadata": {},
   "source": [
    "### Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5171b4ef",
   "metadata": {},
   "source": [
    "The Central Limit Theorem is a statistical theory that describes the behavior of sample means when samples are taken from a population with any distribution. The assumptions of the Central Limit Theorem are:\n",
    "\n",
    "Random Sampling: The samples are drawn from the population randomly and independently.\n",
    "\n",
    "Sample size: The sample size should be large enough, typically greater than or equal to 30, to ensure that the sample mean has a normal distribution.\n",
    "\n",
    "Finite Population: If the population is infinite or very large, then the sample size should be less than 10% of the population.\n",
    "\n",
    "Independence: The sample values should be independent of each other.\n",
    "\n",
    "Finite Variance: The population should have a finite variance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
